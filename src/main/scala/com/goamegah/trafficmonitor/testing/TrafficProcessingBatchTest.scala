package com.goamegah.trafficmonitor.testing

import org.apache.spark.sql.SparkSession
import com.goamegah.trafficmonitor.streaming.TrafficTransformer
import com.goamegah.trafficmonitor.processing.TrafficStatsAggregator

object TrafficProcessingBatchTest {

  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("TrafficProcessingBatchTest")
      .master("local[*]")
      .getOrCreate()

    import spark.implicits._

    // ğŸ‘‰ Choisis un fichier JSON rÃ©el
    val inputPath = "services/orchestrator/data/raw/20250409010002792155.json"
    val df = spark.read
      .option("multiLine", true)
      .json(inputPath)

    println("ğŸ“¥ JSON brut chargÃ© :")
    df.printSchema()
    df.show(2, truncate = false)

    // ğŸ‘‰ Ã‰tape 1 : Transformation
    val transformed = TrafficTransformer.transform(df)(spark)
    println("ğŸ§¼ DonnÃ©es transformÃ©es :")
    transformed.printSchema()
    transformed.show(5, truncate = false)

    // ğŸ‘‰ Ã‰tape 2 : AgrÃ©gation par tronÃ§on
    val aggregated = TrafficStatsAggregator.aggregate(transformed)
    println("ğŸ“Š AgrÃ©gation simple par tronÃ§on :")
    aggregated.show(5, truncate = false)

    // ğŸ‘‰ Ã‰tape 3 : AgrÃ©gation par minute
    val aggregatedByMinute = TrafficStatsAggregator.aggregateByMinute(transformed)
    println("â± AgrÃ©gation par minute :")
    aggregatedByMinute.show(5, truncate = false)

    spark.stop()
  }
}
